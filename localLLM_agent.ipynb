{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977bcb0d-99db-419a-8d5d-f1fd7eb7d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union, Any, Optional, Type\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re\n",
    "from langchain import PromptTemplate\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "from bot.llm_client import AlpacaLLM\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723fb3d6-42e9-44db-8b70-a932554e2771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cbe324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "import random\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str: \n",
    "    \"\"\"useful for when you need to ask with search\"\"\"\n",
    "    url = \"http://127.0.0.1:8000/get_message/\"\n",
    "    message = \"Hello its search\"\n",
    "    user_id = str(random.randint(1, 100))\n",
    "\n",
    "    data = {\n",
    "        \"message\": message,\n",
    "        \"user_id\": user_id\n",
    "    }\n",
    "\n",
    "    #Turn data into json for the request\n",
    "    data = json.dumps(data)\n",
    "\n",
    "    response = requests.post(url, data=data)\n",
    "    return \"DONE1\"\n",
    "\n",
    "@tool\n",
    "def explicit(query: str) -> str: \n",
    "    \"\"\"Function that it use when explicitly asked to do it\"\"\"\n",
    "    url = \"http://127.0.0.1:8000/get_message/\"\n",
    "    message = \"Hello its explicit\"\n",
    "    user_id = str(random.randint(1, 100))\n",
    "\n",
    "    data = {\n",
    "        \"message\": message,\n",
    "        \"user_id\": user_id\n",
    "    }\n",
    "\n",
    "    #Turn data into json for the request\n",
    "    data = json.dumps(data)\n",
    "\n",
    "    response = requests.post(url, data=data)\n",
    "    return \"DONE2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe68a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tools(q):\n",
    "    return [search, explicit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9277e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchs = GoogleSerperAPIWrapper()\n",
    "# tool_google = Tool(\n",
    "#         name=\"Google Search\",\n",
    "#         func=search,\n",
    "#         description=\"useful for when you need to ask with search\"\n",
    "#     )\n",
    "tool_names = [search, explicit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e272163-d79b-450f-8830-6698a417ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = VicunaLLM()\n",
    "llm = AlpacaLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3dd5fd-09c9-4bf1-b944-4dee2f3fac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "Search: A wrapper around custom Search function. Useful for when you need to answer questions about current events. The input is the question to search relavant information.\n",
    "Explicit: Other function that it use when explicitly asked to do it\n",
    "\n",
    "**Strictly** use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [search]\n",
    "Action Input: the input to the action, should be a question.\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "For examples:\n",
    "Question: How old is CEO of Microsoft wife?\n",
    "Thought: First, I need to find who is the CEO of Microsoft.\n",
    "Action: search\n",
    "Action Input: Who is the CEO of Microsoft?\n",
    "Observation: Satya Nadella is the CEO of Microsoft.\n",
    "Thought: Now, I should find out Satya Nadella's wife.\n",
    "Action: search\n",
    "Action Input: Who is Satya Nadella's wife?\n",
    "Observation: Satya Nadella's wife's name is Anupama Nadella.\n",
    "Thought: Then, I need to check Anupama Nadella's age.\n",
    "Action: search\n",
    "Action Input: How old is Anupama Nadella?\n",
    "Observation: Anupama Nadella's age is 50.\n",
    "Thought: I now know the final answer.\n",
    "Final Answer: Anupama Nadella is 50 years old.\n",
    "\n",
    "Another example:\n",
    "Question: Can you run the explicit function?\n",
    "Thought: First, I need to run the explicit function.\n",
    "Action: explicit\n",
    "Action Input: Anything you can think of\n",
    "Observation: This is the result of explicit function\n",
    "Thought: Now the task is finished, and I can write the final answer to tell the users.\n",
    "Final Answer: The function is finished\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "temp_Ins = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Question: {thought}\n",
    "Query: {query}\n",
    "Observation: {observation}\n",
    "\n",
    "### Input:\n",
    "Make a short summary of useful information from the result observation that is related to the question.\n",
    "\n",
    "### Response:\"\"\"\n",
    "\n",
    "prompt_Ins = PromptTemplate(\n",
    "    input_variables=[\"thought\", \"query\", \"observation\"],\n",
    "    template=temp_Ins,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    \"\"\"Schema to represent a prompt for an LLM.\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "\n",
    "            from langchain import PromptTemplate\n",
    "            prompt = PromptTemplate(input_variables=[\"foo\"], template=\"Say {foo}\")\n",
    "    \"\"\"\n",
    "\n",
    "    input_variables: List[str]\n",
    "    \"\"\"A list of the names of the variables the prompt template expects.\"\"\"\n",
    "\n",
    "    template: str\n",
    "    \"\"\"The prompt template.\"\"\"\n",
    "\n",
    "    template_format: str = \"f-string\"\n",
    "    \"\"\"The format of the prompt template. Options are: 'f-string', 'jinja2'.\"\"\"\n",
    "\n",
    "    validate_template: bool = False\n",
    "    \"\"\"Whether or not to try validating the template.\"\"\"\n",
    "    \n",
    "    tools_getter: Callable\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        ############## NEW ######################\n",
    "        tools = self.tools_getter(kwargs[\"input\"])\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8295a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(input_variables=[\"input\", \"intermediate_steps\"],\n",
    "                              template=template,validate_template=False, tools_getter=get_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fd5b16d-013d-412e-8248-7d51b9eba229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eebdeac1-b1e4-410c-b8c4-ede58444666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tool_names, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d40803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=LLMSingleActionAgent(llm_chain=LLMChain(prompt=CustomPromptTemplate(input_variables=['input', 'intermediate_steps'], template=\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nAnswer the following questions as best you can. You have access to the following tools:\\n\\nSearch: A wrapper around custom Search function. Useful for when you need to answer questions about current events. The input is the question to search relavant information.\\nExplicit: Other function that it use when explicitly asked to do it\\n\\n**Strictly** use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [search]\\nAction Input: the input to the action, should be a question.\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nFor examples:\\nQuestion: How old is CEO of Microsoft wife?\\nThought: First, I need to find who is the CEO of Microsoft.\\nAction: search\\nAction Input: Who is the CEO of Microsoft?\\nObservation: Satya Nadella is the CEO of Microsoft.\\nThought: Now, I should find out Satya Nadella's wife.\\nAction: search\\nAction Input: Who is Satya Nadella's wife?\\nObservation: Satya Nadella's wife's name is Anupama Nadella.\\nThought: Then, I need to check Anupama Nadella's age.\\nAction: search\\nAction Input: How old is Anupama Nadella?\\nObservation: Anupama Nadella's age is 50.\\nThought: I now know the final answer.\\nFinal Answer: Anupama Nadella is 50 years old.\\n\\nAnother example:\\nQuestion: Can you run the explicit function?\\nThought: First, I need to run the explicit function.\\nAction: explicit\\nAction Input: Anything you can think of\\nObservation: This is the result of explicit function\\nThought: Now the task is finished, and I can write the final answer to tell the users.\\nFinal Answer: The function is finished\\n\\n### Input:\\n{input}\\n\\n### Response:\\n{agent_scratchpad}\", tools_getter=<function get_tools at 0x000001F1BD3231A0>), llm=AlpacaLLM()), output_parser=CustomOutputParser(), stop=['\\nObservation:']), tools=[StructuredTool(name='search', description='search(query: str) -> str - useful for when you need to ask with search', args_schema=<class 'pydantic.v1.main.searchSchemaSchema'>, func=<function search at 0x000001F18B62CA40>), StructuredTool(name='explicit', description='explicit(query: str) -> str - Function that it use when explicitly asked to do it', args_schema=<class 'pydantic.v1.main.explicitSchemaSchema'>, func=<function explicit at 0x000001F18B62D300>)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b323da5-7fc1-4407-a5b4-5d749f94b354",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_executor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# agent_executor.run(\"How much is the salary of number 8 of Manchester United?\")\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# agent_executor.run(\"How old is Elon Musk's ex-girlfriend?\")\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# agent_executor.run(\"What is the population of Vietnam?\")\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# agent_executor.run(\"Where was the first president of Vietnam born?\")\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# agent_executor.run(\"What is the population of the country that won World Cup 2022?\")\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43magent_executor\u001b[49m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello my name is Zain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent_executor' is not defined"
     ]
    }
   ],
   "source": [
    "# agent_executor.run(\"How much is the salary of number 8 of Manchester United?\")\n",
    "# agent_executor.run(\"How old is Elon Musk's ex-girlfriend?\")\n",
    "# agent_executor.run(\"What is the population of Vietnam?\")\n",
    "# agent_executor.run(\"Where was the first president of Vietnam born?\")\n",
    "# agent_executor.run(\"What is the population of the country that won World Cup 2022?\")\n",
    "agent_executor.run(\"Hello my name is Zain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e4ccb-988a-4ccd-b832-99b4bc06dcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
