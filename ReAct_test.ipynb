{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, SerpAPIWrapper, LLMChain\n",
    "from typing import List, Union, Any, Optional, Type\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re\n",
    "from langchain import PromptTemplate\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.callbacks.manager import AsyncCallbackManagerForToolRun, CallbackManagerForToolRun\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "\n",
    "from llm_client import AlpacaLLM\n",
    "from typing import Callable\n",
    "import json\n",
    "import requests\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "import random\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SERPER_API_KEY\"] = 'f90fe84e78ef9d2d8e377ab5c6fe3a4a25f42ef0'\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true'\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = 'https://api.smith.langchain.com'\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = 'ls__413a7563fa034592be6c6a241176932a'\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = 'LLM Patient Monitoring'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def send_api_to_medic(query: str) -> str: \n",
    "    \"\"\"Function that send a message to the medic if the patient has a symtomps that he tells to the chatbot, and only run it once.\n",
    "    The query is the message that the patient send to the chatbot.\"\"\"\n",
    "    url = \"http://127.0.0.1:8000/get_message/\"\n",
    "    # message = \"Hello its send api\"\n",
    "    user_id = str(random.randint(1, 100))\n",
    "\n",
    "    data = {\n",
    "        \"message\": query,\n",
    "        \"user_id\": user_id\n",
    "    }\n",
    "\n",
    "    #Turn data into json for the request\n",
    "    data = json.dumps(data)\n",
    "\n",
    "    response = requests.post(url, data=data)\n",
    "    return ' Success sending message. Please provide search query to get the result.'\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str: \n",
    "    \"\"\"Function that it use when you searching up something on google\"\"\"\n",
    "    return GoogleSerperAPIWrapper().run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [send_api_to_medic, search]\n",
    "tool_names = [i.name for i in tools_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You're name is PANDA, an assitant for patient hemodialysis. Your job to be a companion and assist the patient or user for their questions. You must gives helpful, detailed, and polite answers to the user's questions.\n",
    "\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Answer the following questions as best you can. You have access to the following tools, and user it based on the context of the questions:\n",
    "\n",
    "{tools}\n",
    "\n",
    "**Strictly** use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do, in every step after Observation\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action, should be a question.\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "For examples of how to use the tools, see the examples below.:\n",
    "Question: I have a really bad headache?\n",
    "Thought: First, I need send a message to the medic.\n",
    "Action: send_api_to_medic\n",
    "Action Input: \"I have a really bad headache?\"\n",
    "Observation: Success sending message. Please provide search query to get the result.\n",
    "Thought: Now, I should start the search.\n",
    "Action: search\n",
    "Action Input: What causes a really bad headache?\n",
    "Observation: Bad headache can be caused by a number of things, including dehydration, stress, and tension.\n",
    "Thought: I now know the final answer.\n",
    "Final Answer: Anupama Nadella is 50 years old.\n",
    "\n",
    "Sometimes user's questions can be answered directly without using any tools.\n",
    "For example:\n",
    "Question: Hello, how are you?\n",
    "Thought: I can answer this question directly.\n",
    "Final Answer: I am doing well, thank you for asking.\n",
    "\n",
    "If the questions does not require any tools, you can answer directly without using any tools, and to the Final Answer directly.\n",
    "\n",
    "Begin the task by answering the following question, **remember** to follow the format above.:\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "{agent_scratchpad}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    \"\"\"Schema to represent a prompt for an LLM.\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "\n",
    "            from langchain import PromptTemplate\n",
    "            prompt = PromptTemplate(input_variables=[\"foo\"], template=\"Say {foo}\")\n",
    "    \"\"\"\n",
    "\n",
    "    input_variables: List[str]\n",
    "    \"\"\"A list of the names of the variables the prompt template expects.\"\"\"\n",
    "\n",
    "    template: str\n",
    "    \"\"\"The prompt template.\"\"\"\n",
    "\n",
    "    template_format: str = \"f-string\"\n",
    "    \"\"\"The format of the prompt template. Options are: 'f-string', 'jinja2'.\"\"\"\n",
    "\n",
    "    validate_template: bool = False\n",
    "    \"\"\"Whether or not to try validating the template.\"\"\"\n",
    "    \n",
    "    tools_getter: List[StructuredTool]\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        ############## NEW ######################\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in self.tools_getter]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools_getter])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(input_variables=[\"input\", \"intermediate_steps\"],\n",
    "                              template=template,validate_template=False, tools_getter=tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        \n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        \n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        \n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        if match:\n",
    "\n",
    "        \n",
    "            action = match.group(1).strip() #Action send_api\n",
    "            action_input = match.group(2) #Action Input \"What is the weather today?\"\n",
    "            # Return the action and action input\n",
    "            return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "        \n",
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AlpacaLLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain.agents.agent.LLMSingleActionAgent` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zain\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Hello, who are you?\n",
      "Thought: I can answer this question directly.\n",
      "Final Answer: My name is Panda, your assistant for patient hemodialysis.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'My name is Panda, your assistant for patient hemodialysis.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"Hello, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
